c = confiance aux données, plus c'est grand plus le poids est fort
	on essaye donc de mieux classer et de tout inclure sans laisser de place à l'erreur
	
g = en parallèle au sigma, valeur d'une gaussienne
	plus g est grand, plus sigma est petit 
	permet d'influer la taille des régions


https://www.csie.ntu.edu.tw/~cjlin/libsvm/

options:
-s svm_type : set type of SVM (default 0)
	0 -- C-SVC
	1 -- nu-SVC
	2 -- one-class SVM
	3 -- epsilon-SVR
	4 -- nu-SVR
-t kernel_type : set type of kernel function (default 2)
	0 -- linear: u'*v
	1 -- polynomial: (gamma*u'*v + coef0)^degree
	2 -- radial basis function: exp(-gamma*|u-v|^2)
	3 -- sigmoid: tanh(gamma*u'*v + coef0)
-d degree : set degree in kernel function (default 3)
-g gamma : set gamma in kernel function (default 1/num_features)
-r coef0 : set coef0 in kernel function (default 0)
-c cost : set the parameter C of C-SVC, epsilon-SVR, and nu-SVR (default 1)
-n nu : set the parameter nu of nu-SVC, one-class SVM, and nu-SVR (default 0.5)
-p epsilon : set the epsilon in loss function of epsilon-SVR (default 0.1)
-m cachesize : set cache memory size in MB (default 100)
-e epsilon : set tolerance of termination criterion (default 0.001)
-h shrinking: whether to use the shrinking heuristics, 0 or 1 (default 1)
-b probability_estimates: whether to train a SVC or SVR model for probability estimates, 0 or 1 (default 0)
-wi weight: set the parameter C of class i to weight*C, for C-SVC (default 1)

The k in the -g option means the number of attributes in the input data.



Iris :  97,33%; (73/75)
		96,40%; (72/75)
Ensuite on le fait sur une commande batch puis dans un programme Java.

.\windows\svm-train.exe -c 1 -g ..\Iris\iris.app
.\windows\svm-predict.exe ..\Iris\iris.app ..\Iris\iris.app.model ..\Iris\iris.result
Notre résultat ? On est trop forts, on a eu la ligne suivante :
Accuracy = 96% (72/75) (classification)
ET OUI MON POTE !!


Batch TODO :
cmd /u svm-predict.exe -c %2 -g %3 %1\%1.app
cmd /u svm-predict.exe %1\%1.app %1\%1.app.model %1\%1.result
